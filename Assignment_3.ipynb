{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tajfsk_7JY3E"
      },
      "source": [
        "**Note to grader:** Each question consists of parts, e.g. Q1(i), Q1(ii), etc. Each part must be graded  on a 0-4 scale, following the standard NJIT convention (A:4, B+: 3.5, B:3, C+: 2.5, C: 2, D:1, F:0). \n",
        "The total score must be re-scaled to 100 &mdash; that should apply to all future assignments so that Canvas assigns the same weight on all assignments. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPnHTf9MfT5X"
      },
      "outputs": [],
      "source": [
        "# Grader's area\n",
        "\n",
        "import numpy as np\n",
        "M = np.zeros([10,10])\n",
        "maxScore = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SArgW_Vq-uTh"
      },
      "source": [
        "# **Assignment 3**\n",
        "\n",
        "The goal in this assignment to work a little more with Python, do some practice with logistic regression, and reflect on how it can fail to work on linearly separable data. You will also work with a support vector classifier. All that, still on \"toy\" data sets. \n",
        "\n",
        "We will work with the first 'real' data sets in the next assignment. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlFM4hig-uTj"
      },
      "source": [
        "## **Preparation Steps**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3alYkjM-uTk"
      },
      "outputs": [],
      "source": [
        "# Import all necessary python packages\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from numpy import array  \n",
        "from numpy.linalg import norm\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTVa-fum-uTt",
        "outputId": "869b6066-05c0-40e2-8d6c-e464ededc0f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "URL: https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\n"
          ]
        }
      ],
      "source": [
        "# Reading-in the Iris data\n",
        "\n",
        "s = os.path.join('https://archive.ics.uci.edu', 'ml',\n",
        "                 'machine-learning-databases', 'iris','iris.data')\n",
        "s = s.replace(\"\\\\\",\"/\");\n",
        "print('URL:', s)\n",
        "df = pd.read_csv(s,header=None,encoding='utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "cqzyfFCC-uTz",
        "outputId": "cc990d31-dd12-4447-f02e-0d05fab223ee"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Select setosa and versicolor for binary classification\n",
        "y = df.iloc[0:100, 4].values\n",
        "y = np.where(y == 'Iris-setosa', -1, 1)\n",
        "\n",
        "# Extract sepal length and petal length\n",
        "X = df.iloc[:100, [0, 2]].values\n",
        "\n",
        "# Plot data\n",
        "plt.scatter(X[:50, 0], X[:50, 1],\n",
        "            color='red', marker='o', label='setosa')\n",
        "plt.scatter(X[50:100, 0], X[50:100, 1],\n",
        "            color='blue', marker='x', label='versicolor')\n",
        "\n",
        "plt.xlabel('sepal length [cm]')\n",
        "plt.ylabel('petal length [cm]')\n",
        "plt.legend(loc='upper left')\n",
        "\n",
        "\n",
        "# plt.savefig('images/02_06.png', dpi=300)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYEgTzp0s5BN"
      },
      "outputs": [],
      "source": [
        "# Function for visualizing decision regions\n",
        "\n",
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "def plot_decision_regions(X, y, classifier, resolution=0.02):\n",
        "\n",
        "    # Setup marker generator and color map\n",
        "    markers = ('s', 'x', 'o', '^', 'v')\n",
        "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
        "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
        "\n",
        "    # Plot the decision surface\n",
        "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
        "                           np.arange(x2_min, x2_max, resolution))\n",
        "    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
        "    Z = Z.reshape(xx1.shape)\n",
        "    plt.contourf(xx1, xx2, Z, alpha=0.3, cmap=cmap)\n",
        "    plt.xlim(xx1.min(), xx1.max())\n",
        "    plt.ylim(xx2.min(), xx2.max())\n",
        "\n",
        "    # Plot class examples\n",
        "    for idx, cl in enumerate(np.unique(y)):\n",
        "        plt.scatter(x=X[y == cl, 0], \n",
        "                    y=X[y == cl, 1],\n",
        "                    alpha=0.8, \n",
        "                    c=colors[idx],\n",
        "                    marker=markers[idx], \n",
        "                    label=cl, \n",
        "                    edgecolor='black')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phGY3AEGn3dz"
      },
      "source": [
        "---------------------------------------------------------------\n",
        "---------------------------------------------------------------\n",
        "---------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pe9kKR3J-uUA"
      },
      "source": [
        "## <font color = 'blue'> **Question 1. Practice with logistic regression** </font>\n",
        "\n",
        "First, let's load the textbook's implementation of logistic regression with gradient descent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSRTXCwz-uUA"
      },
      "outputs": [],
      "source": [
        "class LogisticRegressionGD(object):\n",
        "\n",
        "    \"\"\"Logistic Regression Classifier using gradient descent.\n",
        "\n",
        "    Parameters\n",
        "    ------------\n",
        "    eta : float\n",
        "      Learning rate (between 0.0 and 1.0)\n",
        "    n_iter : int\n",
        "      Passes over the training dataset.\n",
        "    random_state : int\n",
        "      Random number generator seed for random weight\n",
        "      initialization.\n",
        "\n",
        "\n",
        "    Attributes\n",
        "    -----------\n",
        "    w_ : 1d-array\n",
        "      Weights after fitting.\n",
        "    loss_ : list\n",
        "      Logistic loss function value in each epoch.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, eta=0.05, n_iter=100, random_state=1):\n",
        "        self.eta = eta\n",
        "        self.n_iter = n_iter\n",
        "        self.random_state = random_state\n",
        "\n",
        "    def fit(self, X, y):\n",
        "\n",
        "        \"\"\" Fit training data.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : {array-like}, shape = [n_examples, n_features]\n",
        "          Training vectors, where n_examples is the number of examples and\n",
        "          n_features is the number of features.\n",
        "        y : array-like, shape = [n_examples]\n",
        "          Target values.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        self : object\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        rgen = np.random.RandomState(self.random_state)\n",
        "        self.w_ = rgen.normal(loc=0.0, scale=0.01, size=1 + X.shape[1])\n",
        "        self.loss_ = []\n",
        "\n",
        "        for i in range(self.n_iter):\n",
        "            net_input = self.net_input(X)\n",
        "            output = self.activation(net_input)\n",
        "            errors = (y - output)\n",
        "            self.w_[1:] += self.eta * X.T.dot(errors)\n",
        "            self.w_[0] += self.eta * errors.sum()\n",
        "            \n",
        "            # Compute the logistic `loss` \n",
        "            loss = -y.dot(np.log(output)) - ((1 - y).dot(np.log(1 - output)))\n",
        "            self.loss_.append(loss)\n",
        "        return self\n",
        "    \n",
        "    def net_input(self, X):\n",
        "        \"\"\"Calculate net input\"\"\"\n",
        "        return np.dot(X, self.w_[1:]) + self.w_[0]\n",
        "\n",
        "    def activation(self, z):\n",
        "        \"\"\"Compute logistic sigmoid activation\"\"\"\n",
        "        return 1. / (1. + np.exp(-np.clip(z, -250, 250)))\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Return class label after unit step\"\"\"\n",
        "        return np.where(self.net_input(X) >= 0.0, 1, 0)\n",
        "        # Equivalent to:\n",
        "        # return np.where(self.activation(self.net_input(X)) >= 0.5, 1, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMYBgs4E-uUF"
      },
      "source": [
        "Below you can see the first 3 data points of the data set, all labeled as 'setosa'. Let's set the numerical value for 'setosa' to 1. (i.e. y = 1). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyoLJVet-uUG",
        "outputId": "cdcefa93-a3d5-4925-8d96-7657657e30e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.1, 1.4],\n",
              "       [4.9, 1.4],\n",
              "       [4.7, 1.3]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "X[0:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPbGfqmf-uUK"
      },
      "source": [
        "\n",
        "Suppose the initial weights of the logistic neuron are w0 = 0.1, w1 = -0.2, w2 = 0.1.\n",
        "\n",
        "<font color = 'blue'> **Q1-1**.  </font> Write the weights after processing data points 0,1,2, with learning rate $\\eta=0.1$ and show your calculations. This is similar to the previous assignment, only done now for the logistic neuron. You can also use *LogisticRegressionGD* to check your calculations. <br>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3U8_BJ0XO-Gu",
        "outputId": "bcd36373-4746-467c-cbc4-a3ee9da4c43c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.03143198860617462 -0.5496968581085094 0.004004784048644475\n"
          ]
        }
      ],
      "source": [
        "### DATA POINT 0: (5.1, 1.4)\n",
        "import math\n",
        "\n",
        "n = 0.1\n",
        "w0 = 0.1\n",
        "w1 = -0.2\n",
        "w2 = 0.1\n",
        "\n",
        "x1 = 5.1\n",
        "x2 = 1.4\n",
        "y_ = 1\n",
        "\n",
        "### Net_input\n",
        "z = w0 + w1*x1 + w2*x2\n",
        "\n",
        "### Output\n",
        "y_hat = 1 / (1 + math.exp(-z))\n",
        "\n",
        "w0 = w0 - n*(y_ - y_hat)\n",
        "w1 = w1 - n*(y_ - y_hat)*x1\n",
        "w2 = w2 - n*(y_ - y_hat)*x2\n",
        "\n",
        "print(w0, w1, w2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlNBmLm2QsyG",
        "outputId": "04e2f8e9-9b2e-4613-f815-0eadd04ba407"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.06200891241119834 -1.0075572730936369 -0.12681247737567763\n"
          ]
        }
      ],
      "source": [
        "### DATA POINT 1: (4.9, 1.4)\n",
        "import math\n",
        "\n",
        "n = 0.1\n",
        "w0 = 0.03143198860617462\n",
        "w1 = -0.5496968581085094\n",
        "w2 = 0.004004784048644475\n",
        "\n",
        "x1 = 4.9\n",
        "x2 = 1.4\n",
        "y_ = 1\n",
        "\n",
        "### Net_input\n",
        "z = w0 + w1*x1 + w2*x2\n",
        "\n",
        "### Output\n",
        "y_hat = 1 / (1 + math.exp(-z))\n",
        "\n",
        "w0 = w0 - n*(y_ - y_hat)\n",
        "w1 = w1 - n*(y_ - y_hat)*x1\n",
        "w2 = w2 - n*(y_ - y_hat)*x2\n",
        "\n",
        "print(w0, w1, w2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BjzODuCRDJ_",
        "outputId": "b2cfcadb-440c-4f2e-84d6-3f1257bb1c65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.16131415045226774 -1.474291891886663 -0.2559092868290679\n"
          ]
        }
      ],
      "source": [
        "### DATA POINT 2: (4.7, 1.3)\n",
        "import math\n",
        "\n",
        "n = 0.1\n",
        "w0 = -0.06200891241119834\n",
        "w1 = -1.0075572730936369\n",
        "w2 = -0.12681247737567763\n",
        "\n",
        "x1 = 4.7\n",
        "x2 = 1.3\n",
        "y_ = 1\n",
        "\n",
        "### Net_input\n",
        "z = w0 + w1*x1 + w2*x2\n",
        "\n",
        "### Output\n",
        "y_hat = 1 / (1 + math.exp(-z))\n",
        "\n",
        "w0 = w0 - n*(y_ - y_hat)\n",
        "w1 = w1 - n*(y_ - y_hat)*x1\n",
        "w2 = w2 - n*(y_ - y_hat)*x2\n",
        "\n",
        "print(w0, w1, w2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After each point being updated individually, the weights are:\n",
        "\n",
        "*   $w_1 = -0.16131415045226774$\n",
        "*   $w_2 = -1.474291891886663$\n",
        "*   Intercept $b = -0.2559092868290679$"
      ],
      "metadata": {
        "id": "GYldx5L41V91"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_Q1 = X[0:3]\n",
        "w_Q1 = np.array([0.1, -0.2, 0.1])\n",
        "\n",
        "NetInput = np.dot(X_Q1, w_Q1[1:]) + w_Q1[0]\n",
        "\n",
        "Q1_Errors = []\n",
        "for i in range(len(X_Q1)):\n",
        "    Error = -1 - (1 / (1 + math.exp(-NetInput[i])))  ## -1 or 1 ?\n",
        "    Q1_Errors.append(Error)\n",
        "w_Q1[0] = sum(Q1_Errors)*0.1 + w_Q1[0]\n",
        "Q1_Dot = np.dot(np.transpose(X_Q1), Q1_Errors)\n",
        "w_Q1[1] = Q1_Dot[0] * 0.1 + w_Q1[1]\n",
        "w_Q1[2] = Q1_Dot[1] * 0.1 + w_Q1[2]\n",
        "print(w_Q1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pobs9-m21TmJ",
        "outputId": "c0822391-44e1-4f14-ea10-9dce0f16ee85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.29669229 -2.14348663 -0.44207321]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On the other hand, following the logistic regression with gradient descent code given above, the weights after evaluating all points are:\n",
        "\n",
        "*   $w_1 = -0.29669229$\n",
        "*   $w_2 = -2.14348663$\n",
        "*   Intercept $b = -0.44207321$"
      ],
      "metadata": {
        "id": "HimkjTccEWj1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0D4ujMt_JW_N"
      },
      "source": [
        "<font color = 'blue'> **Q1-2**.  </font> Given our data $X$, let $X_{d=2}$ and $X_{d=3}$ be the quadratic and cubic features. Using code for polynomial regression from the Regression Code Notebook, generate $X_{d=2}$ and $X_{d=3}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJfl0keEJY5S"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "quadratic = PolynomialFeatures(degree=2)\n",
        "X_quad = quadratic.fit_transform(X)\n",
        "\n",
        "cubic = PolynomialFeatures(degree=3)\n",
        "X_cubic = cubic.fit_transform(X)\n",
        "\n",
        "print('X(Quadratic): ', X_quad)\n",
        "print('X(Cubic): ', X_cubic)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zg1IDKfzJZpk"
      },
      "source": [
        "<font color = 'blue'> **Q1-3**.  </font> Using *LogisticRegressionGD*, fit $X$, $X_{d=2}$ and $X_{d=3}$. Here you should set $\\eta \\leq 0.0001$ and $n_{\\mathit{iter}}\\geq 10000$. For each of these three cases, report the loss function value for the model computed by *LogisticRegressionGD*. (What happens if $\\eta$ is chosen too large or too small?)\n",
        "Here, for a fixed choice of $\\eta$ and $n_{\\mathit{iter}}$, it is expected that the loss value decreases as $d$ increases. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wYFal09ID7Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c30a8f9a-351a-485b-cc2e-38a94ec39e5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-47fe9bb3b84c>:60: RuntimeWarning: divide by zero encountered in log\n",
            "  loss = -y.dot(np.log(output)) - ((1 - y).dot(np.log(1 - output)))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nan\n",
            "nan\n",
            "nan\n"
          ]
        }
      ],
      "source": [
        "LGD_Q1 = LogisticRegressionGD(0.00005, 50000, random_state=5)\n",
        "\n",
        "LGD_Q1.fit(X,y)\n",
        "print(LGD_Q1.loss_[-1])\n",
        "LGD_Q1.fit(X_quad,y)\n",
        "print(LGD_Q1.loss_[-1])\n",
        "LGD_Q1.fit(X_cubic,y)\n",
        "print(LGD_Q1.loss_[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gvcYDePeakx",
        "outputId": "0dd26206-5e13-4e9f-a5a3-6b09920f5b78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "68.77253693123217\n",
            "74.68498394530913\n",
            "31.20879586203386\n"
          ]
        }
      ],
      "source": [
        "LGD_Q1 = LogisticRegressionGD(0.00000000005, 50000, random_state=5)\n",
        "\n",
        "LGD_Q1.fit(X,y)\n",
        "print(LGD_Q1.loss_[-1])\n",
        "LGD_Q1.fit(X_quad,y)\n",
        "print(LGD_Q1.loss_[-1])\n",
        "LGD_Q1.fit(X_cubic,y)\n",
        "print(LGD_Q1.loss_[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNTnSfJnfAgw",
        "outputId": "88a134c2-c034-400c-946e-cac66d3d36da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "68.91721584792816\n",
            "78.74672097222255\n",
            "99.98145355798307\n"
          ]
        }
      ],
      "source": [
        "LGD_Q1 = LogisticRegressionGD(0.000000000000000000000000000005, 50000, random_state=5)\n",
        "\n",
        "LGD_Q1.fit(X,y)\n",
        "print(LGD_Q1.loss_[-1])\n",
        "LGD_Q1.fit(X_quad,y)\n",
        "print(LGD_Q1.loss_[-1])\n",
        "LGD_Q1.fit(X_cubic,y)\n",
        "print(LGD_Q1.loss_[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obtR8nBjh2Sd"
      },
      "source": [
        "*   For a too large $\\eta = 0.00005$, there's a RuntimeWarning: divide by zero encountered in log, having the lost function values to not be computed.\n",
        "*   For a too small $\\eta = 0.000000000000000000000000000005$, the loss function value doesn't decrease as $d$ increases.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HV6DRoDxG1Rl"
      },
      "outputs": [],
      "source": [
        "# Grader's area\n",
        "\n",
        "maxScore = maxScore + 12\n",
        "# M[1,1] = \n",
        "# M[1,2] = \n",
        "# M[1,3] ="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6grYJ9spn6C1"
      },
      "source": [
        "-----------------------\n",
        "-----------------------\n",
        "-----------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zW8T7xf0-uUL"
      },
      "source": [
        "## <font color = 'blue'> **Question 2. A theoretical question** </font>\n",
        "\n",
        "This question is about a theoretical explanation for what you observed in question 1(iii). \n",
        "\n",
        "<br>\n",
        "\n",
        "Suppose $f_1$ is a model that optimally fits the data $(X,y)$, and $f_2$ is another model that optimally fits the data $(X_2,y)$, where $X_2$ are the quadratic features of $X$. Then the loss function value obtained by $f_2$ is **always** going to be at least equal to that for $f_1$. Try to come up with a solid mathematical argument that justifies this claim. [Note: as with anything else, feel free to discuss this on Canvas.]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRk7QbZLH_DY"
      },
      "source": [
        "Let's assume that the loss function used is the same for both models, denoted as $L$.\n",
        "\n",
        "Since $f_1$ is a model that optimally fits the data $(X, y)$, we can say that it minimizes the loss function for the given data:\n",
        "\n",
        "> $L(X, y; f_1) ≤ L(X, y; f)$, for all $f$ models.\n",
        "\n",
        "Similarly, $f_2$ is a model that optimally fits the data $(X_2, y)$, we can say that it minimizes the loss function for the given data:\n",
        "\n",
        "> $L(X_2, y; f_2) ≤ L(X_2, y; f)$, for all $f$ models.\n",
        "\n",
        "We know that $X_2$ is obtained by adding quadratic features to $X$, which means that $X_2$ has more dimensions than $X$. Therefore, any linear model (such as $f_1$) that uses $X$ as input cannot capture the quadratic relationship between the input features, while a quadratic model (such as $f_2$) that uses $X_2$ as input can capture this relationship.\n",
        "\n",
        "Thus, we can say that $f_1$ is a special case of $f_2$, where the quadratic features are not used. Hence, we can use the same function $f_2$ to model both $X$ and $X_2$, and we can write that:\n",
        "\n",
        "> $L(X, y; f_2) ≤ L(X, y; f_1) ≤ L(X, y; f)$, for all $f$ models.\n",
        "\n",
        "The first inequality holds because $f_2$ can capture the quadratic relationship in $X_2$ , which can also benefit the model when $X$ is used as input. The second inequality holds because $f_1$ optimally fits the data $(X, y)$, which means that it minimizes the loss function for that specific data.\n",
        "\n",
        "Therefore, we can conclude that the loss function value obtained by $f_2$ is always going to be at least equal to that for $f_1$, because $f_2$ can model both $X$ and $X_2$, while $f_1$ can only model $X$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJrBDgJYBQZL"
      },
      "outputs": [],
      "source": [
        "# Grader's area\n",
        "\n",
        "maxScore = maxScore + 4\n",
        "# M[2,1] = "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxiK-qoin6_-"
      },
      "source": [
        "-----------------------\n",
        "-----------------------\n",
        "-----------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMEcdAp3-uT-"
      },
      "source": [
        "##  <font color = 'blue'> **Question 3. Logistic Regression: How 'unfair' can it be?**  </font>\n",
        "\n",
        "We have seen that the inductive bias of an SVC guarantees that when the dataset is linearly separable, SVC will return a hyperplane that is at exactly the same distance from the two classes.  But what about logistic regression? Can we guarantee that it can also be at least partially fair?\n",
        "\n",
        "The answer is **no**. We can  demonstrate how logistic regression can be 'unfair' by constructing a dataset with the properties that: <br> \n",
        "\n",
        "**a.** the data set is linearly separable, and  <br>\n",
        "**b.** the optimal logistic regression model corresponds to a hyperplane that nearly 'touches' one of the two classes - that is, it has a very big margin with respect to one of the two classes, and a very small margin with respect to the other class.  <br>\n",
        "\n",
        "**Hint**: Try small datasets. <br>\n",
        "**Note**: It's best to use fresh variables for your dataset, since the previous values of $X,y$ will be reused in Question 4.\n",
        "Demonstrate your answer as follows: <br>\n",
        "\n",
        "<font color = 'blue'> **Q3-1**.  </font>\n",
        " Plot the data points, as we did above for the Iris data set. This will show that your data set is linearly separable. <br>\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "mTPbCgxvkoA9",
        "outputId": "b7387441-d54d-460a-aff0-eed191dfee5c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "X1 = [0,-0.5]\n",
        "X2 = [1,-1]\n",
        "X3 = [0.5, -0.5]\n",
        "X4 = [1,0]\n",
        "X_Q3 = np.array([X1, X2, X3, X4])\n",
        "Y_Q3 = np.array([0, 0, 1, 1])\n",
        "\n",
        "plt.scatter(X_Q3[:2, 0], X_Q3[:2, 1],\n",
        "            color='red', marker='o', label='Y = 0')\n",
        "plt.scatter(X_Q3[2:4, 0], X_Q3[2:4, 1],\n",
        "            color='blue', marker='x', label='Y = 1')\n",
        "\n",
        "plt.xlabel('X1')\n",
        "plt.ylabel('X2')\n",
        "plt.legend(loc='lower left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMkJoVV3Rn9z"
      },
      "source": [
        "<font color = 'blue'> **Q3-2**.  </font> Calculate the optimal logistic neuron weights using the function *LogisticRegressionGD* from Question 1. <br>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGSkDJs9sk2S",
        "outputId": "00024423-2389-4164-e03c-2b8b442f6af8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 3.46720199  4.83901202 10.20801975]\n"
          ]
        }
      ],
      "source": [
        "LGD_Q3 = LogisticRegressionGD(0.001, 100000, random_state=1)\n",
        "LGD_Q3.fit(X_Q3, Y_Q3)\n",
        "print(LGD_Q3.w_)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The coefficients are:\n",
        "\n",
        "*   $w_1 = 3.46720199$\n",
        "*   $w_2 = 4.83901202$\n",
        "*   Intercept $b = 10.20801975$"
      ],
      "metadata": {
        "id": "-ej3UIW0rIzV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFSP5uxeRs3T"
      },
      "source": [
        "<font color = 'blue'> **Q3-3**. </font>  Plot the decision regions to demonstrate how the learned separation line is unfair."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "I3sWD19TuCv6",
        "outputId": "bf5b4fa1-ee69-43fe-fd44-a83be4522b96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-a8435fe16d39>:25: UserWarning: You passed a edgecolor/edgecolors ('black') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
            "  plt.scatter(x=X[y == cl, 0],\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAdHUlEQVR4nO3df5BU5Z3v8c836kYqzBAcERl/hJEMF8e4JkDaaDCXNYlB6zYSWRbdzL2xYpa1EovsWhXUa7G1htpa07trst4YN5SxJpu5haCzIrNryCrcrmBx3RZvmUzUpIMuRhg2KLiAu0RRv/ePc7qnmekeBma6z9Pd71fV1PR5+nDme2yGj+c5z/Mcc3cBABCa9yVdAAAA5RBQAIAgEVAAgCARUACAIBFQAIAgnZp0AdXQ2nqmT58+M+kyAABjsHPns6+7+7Th7Q0ZUNOnz9Q99+xIugwAwBgsXmyvlGuniw8AECQCCgAQJAIKABCkhrwHVc773ndUbW27ddppv026lIqOHj1d+/efq/feOy3pUgAgcU0TUG1tuzVjRotaW2fKzJIuZwR316FD+yXt1muvdSRdDgAkrmm6+E477bdqbW0LMpwkyczU2toW9BUeANRS0wSUpGDDqSD0+gCglpoqoAAA9YOAqqEnn9ysj3/8v2ju3A/rW9+6O+lyACBoBFSNvPvuu/r617+qhx/+kZ5++gX19a3TL37xQtJlAUCwmmYU34m49sqP6/Br+0a0t0w7S49tfeakjvnsszldcMGHNXPmBZKk6667Xo8//pjmzOkaV60A0KgIqDIOv7ZPuTNHrFuoVJnQGqu9e/fonHPOK263t5+rZ5/9l5M+HgA0Orr4AABBIqBqZMaMc7Rnz6vF7cHB3Zox45wEKwKAsBFQNTJ37sf10ku/0iuv/Kvefvtt/cM/PKSrr16cdFkAECzuQdXIqaeeqkzmO1q69HN699139YUvfEkXXnhR0mUBQLAIqDJapp1VdkBEy7SzxnXcq666Rldddc24jgEAzYKAKuNkh5IDACYO96AAAEEioAAAQSKgAABBIqAAAEEioAAAQSKgauiWW76kzs6zdNllH0m6FAAIHgFVgfvo2yfjhhtu1COPbB7/gQCgCRBQZfT0SPfdNxRK7tF2T8/4jvvJT35KU6eeMd7yAKApEFDDuEtvvin19Q2F1H33RdtvvjkxV1IAgONjJYlhzKSvfjV63dcXfUnS0qVRu1lytQFAM+EKqozSkCognACgtgioMgrdeqVK70kBAKqPgBqm9J7T0qXS1q3R99J7Uifrpptu0FVXXaadO3+piy46Vz/84fcnrnAAaDDcgxrGTJo8+dh7ToXuvsmTx9fN9/3vr5uYIgGgCRBQZdx4Y3SlVAijQkhxDwoAaifRLj4zW2RmvzSznWZ2e5n3bzSz18zsufjry7WrbfRtAEB1JXYFZWanSLpP0mcl7Zb0jJltcvcXhu263t1vmYif6e6ygJPGGYUBAEVJXkGlJO1095fd/W1JD0m6tlo/7OjR03Xo0P5gQ8DddejQfh09enrSpQBAEJK8B3WOpFdLtndLurTMfkvN7FOS8pL+1N1fLbOPzGyFpBWSNG3a+SPe37//XEm79frrr42z7Oo5evT0uE4AQOiDJPolrXP3t8zsjyX9QNKV5XZ097WS1kpSZ+f8EZdJ7713ml57raOatQIAJlCSXXx7JJ1Xsn1u3Fbk7vvd/a148wFJ82pUGwAgYUkG1DOSOs2sw8x+R9L1kjaV7mBmM0o2F0t6sYb1AQASlFgXn7u/Y2a3SPqxpFMkPejuz5vZNyTtcPdNklaa2WJJ70g6IOnGpOoFANRWoveg3P1xSY8Pa/uzktd3SLqj1nUBAJLHWnwAgCARUACAIBFQAIAgEVAAgCARUACAIBFQAIAgEVAAgCARUACAIBFQAIAgEVAAgCARUACAIBFQAIAgEVAAgCARUACAIBFQAIAgEVAAgCARUACAIBFQAIAgEVAAgCARUACAIBFQAIAgEVAAgCA1ZED9x39IuVz0BQCoT6cmXUA1/PaNI8r3/UyDh1uUz3eouzvpigAAJ6ohA+qCqW9o/dKH1Z+drMyWtDID06W2NklSe7sILACoAw0ZUPrAB6RUSumUlO69S/2Dc4tvFQJr4dI2pVIJ1ggAGFVjBlSp7m6lSzbTvXdp9cAyZXvmKdvXWmwnsAAgLI0fUMN1d2uNJPXeXmwqBFY+31Fsmz1bBBYAJKj5Aqqg5EbUGkn9mQ3KDcwqtmW3z2OABQAkqHkDapj0qq5jugL7MxuGBljE2i9uI7AAoEYIqArSq7qUzq2T8nlJUv/g3GMGWJRDlyAwsdwls8rbaGyJBpSZLZL0t5JOkfSAu9897P33S/p7SfMk7Ze03N131azAVKqYOmlJ6dw6re67RPmeGcfu19LCnCtggm3eLB05Ii1ZEoWSu7RxozRpkrRoUdLVoRYSCygzO0XSfZI+K2m3pGfMbJO7v1Cy202S3nD3D5vZ9ZK+KWl57auNpVJak5KkA8PeOKD+zAvMuQImiHsUTtu2RdtLlkThtG2bdMUVXEk1iySvoFKSdrr7y5JkZg9JulZSaUBdK+nP49ePSPqOmZm7ey0LHYtCl2B/dnKxrVyXIN2AwPGZRaEkRaFUCKorrhi6okLjSzKgzpH0asn2bkmXVtrH3d8xs4OS2iS9PvxgZrZC0gpJOn/atGrUe3zx5OCCYpdg32xJ0uDhFmX7WplzBYxBIaQK4SQRTs2mYQZJuPtaSWslaX5nZxhXWIUuwdzDxabVfZdEk4SzHWpvj9qYcwWMVLjnVGrjRkKqmSQZUHsknVeyfW7cVm6f3WZ2qqQpigZL1JeS9FmTiudc7Z9VPJPs9iiwVq1KqD4gMIVwKtxzKr0HJRFSzSLJgHpGUqeZdSgKousl/eGwfTZJ+qKk/yvp9yVtDfH+04kqN+eqd9cCZW6bM9TY1kZgoWmZRaP1Su85Fe5JTZpEODULS/LfezO7RtK3FQ0zf9Dd/8LMviFph7tvMrPTJf1Q0scUDZ27vjCoYjTzOzt9xz33VLHyKsjljplz1btrgQZb5qj94qEBFowIRLNhHlRzWLzYnnX3+cPbEw2oaqnLgBoul9PqvkuKm/nDMzTYMocBFgAaTqWAaphBEg2nOOcqltus1X17lb2/S9lsV7F54UIGWABoTARUvSgEVu9dxabVA8uKgbVw4TG7AkDdI6DqzbBV2NV7l5ZvX6l8X4ukeK4VIwIBNAACqt51d2v97M1D2/m8lm9fGY0IbBsaYEFgAag3BFQjKO3TS6W0fvZm9WefKjYVhrDzuBAA9YSAakQjllyKB1hs6VJm+6SR+8+kSxBAeAioZlBccmndyPdKugSZcwUgJARUMyk3vC/uElzdt1caiJryh2coM0CXIIBkEVCoPOdqSxePvAeQGAIKI1Wac7WlS5lB5lwBqA0CCpWVmXO1emBZ8ZH3g0emFicJE1QAJhoBhbHr7o6CqvDI+957tXz7SmV72pXNdhR3I7AATAQCCicvniRc+pj73l0LlO1pVz7fodmzh3YlsACcKAIK41NmzlV/drJ6ty9QfmBo+aV8voMBFgBOCAGFiRUHVjo3tPxSf3ayMlvS0YjAePml9nbmWgEYHQGF6ijp00unpHTvXeofnFtsKwQWz7cCUAkBhdro7j7mMffpeBX2bE+7sn2txXYCC0ABAYVkdHdrffcBqffeYlMhsPL5oRGBs2czwAJoVgQUklVyI2p99wH1Z55SbmCWpGjJpez2dgZYAE2KgEJQ0qu6SroCo8AqDrAYrq2NOVdAAyOgELT0qi6lS5ZcKlXaJcicK6DxEFAIX4X+vUKXIHOugMZEQKGupVd1MecKaFAEFOrfCcy5KvNHAASKgELjKTPnavXAMuX7ohtVg4dblO1rZc4VEDgCCo2vsAp77uFoO5+Pnm/VM0/ZbIfa26Nm5lwBYSGg0DwK6ZNKaY2k/swG5fbPkvZHzdntUWCtWpVYhQBKEFBoWsfOuYoCK/NiWpnbSuZctbURWEBCCCggFo0IXCfl85Kk/sG5xcBqv3hogAUjAoHaIKCAUqlUsSswLSmdW6fVfZdIA9Hb2X1diazC7i6ZVd4GGlEiAWVmZ0haL2mmpF2S/sDd3yiz37sq/tOgX7v74lrViDBdeeutOnTw4Ij21ilTtPWeeyb+B6ZSWlMaRHFgZe/vUjbbVWyu5pJLmzdLR45IS5ZEoeQubdwoTZokLVpUnZ8JhGDUgDKzVknT3P2lYe2/6+4/G8fPvV3SFne/28xuj7dvK7PfEXf/6Dh+DhrMoYMHtWPKlBHt88uEVlUUAqtkrlVu/6xiYC1ceMyu4+YehdO2bdH2kiVROG3bJl1xBVdSaGwVA8rM/kDStyXtM7PTJN3o7s/Eb/dImlvhj47FtZIWxq9/ICmr8gEFhKlkrlVaUn+mX7273lC+b2jJpYkYEWgWhZIUhVIhqK64YuiKCmhUo11B/U9J89x9r5mlJP3QzO5w90cljffXYrq7741f/5ukMktVS5JON7Mdkt6RdLe7b6x0QDNbIWmFJJ0/bdo4ywNOTLkll3p3LVDmtjnFJZdKnUiXYCGkCuEkEU5oDqMF1CmFEHH3nJn9nqR/NLPzJPnxDmxmT0o6u8xbd5ZuuLubWaXjfcjd95jZBZK2mtnA8O7GkuOslbRWkuZ3dh63PmDCDV9yKbdZ/dmnRuxW2iU4liuswj2nUhs3ElJofKMF1GEzm1UIhPhKaqGkjZIuOt6B3f0zld4zs9+Y2Yz4mDMk7atwjD3x95fNLCvpY5LKBhQQnFRK6TJXSaVdgpmvxMtYtLSWnXNVCKfCPafSe1ASIYXGNlpA3axhXXnuftjMFkm6Y5w/d5OkL0q6O/7+2PAdzGyqpP9097fM7ExJn5SUGefPRZ1rnTKl7ICI1jIDJ0I2Wpfg8DlXkyYde8+pcE9q0iTCCY3N3Mv3hpnZy5L+TtLfuPu7cdt0SX8jaY67zz/pH2rWJmmDpPMlvaJomPkBM5sv6WZ3/7KZXS7pe5Lek/Q+Sd929++P5fjzOzt9RzWGHAPVlMtFc65i+cMzNNgSBdYXvsA8KDSuxYvt2XKZMlpATZX0l4quXL4m6WJJtyq6irnf3d+rXrnjQ0ChIcSBld3XJZ01NI6o/eI2VrNAQ6kUUBW7+OKJszeb2dckPSlpUNIn3H139coEUFQy56pg9cAyZbd0KTM48XOugNCMNg/qg5K+KelSSYskXSPpR2b2NXffWpvyAJReLq2RpN67tHz7SuV7orbBI1PHPCIQqCfHuwf1XUX3ft6J2z4at73i7jfUqsgTRRcfmkpvr5ZvX6lBtUszO4rNBBbqxQl38Un61PDuPHd/TtLlZvZHE1wfgJPV3a31szerPzu52NS7a4EyX2lX++Udmh09SJhuQNSdildQ9YwrKDS9XK44dF0tQ8svtV/ewQALBOdkrqAA1Kt4kvDwuVaZLWllBruKj7mXeL4VwkVAAY1s+PJLhVXYB6O2zIvp4ohAugARGgIKaCYlq7BLUWAt375S2Z52Zftao8a2NgILQSCggGbW3a313Qek3nuLTYXAyuc7Kv0RoCYIKADHpM767gPqzzyl3MCsEbtl93XRJYiaIaAAjJBe1XVMV2ARXYKoIQIKwNgdp0uwMOdKIrAwfgQUgBNXpkuwd/sC5QeG5lzl88y5wvgQUADGrdzzrTJb0soMTC8+8r69nQEWODEEFICJUWnOVawQWAuXttH9hzEhoABUR5k5V6sHlinbM0/ZnrixpZXAQkUEFIDa6O6OHheSezDazueHAivbUVx+afZsBlggQkABqK1C+qRSWiOpP7NBuf2zpP1Rc3Z7FFg8LgQEFIBEDZ9z1Z/ZEK0ReNvQY+7V1kZgNSECCkBQohGB66R8XpLUPzi3GFjtF7cV92NEYOMjoACEJ5UqdgWmJaVz67S67xJpIHo7u6+LEYFNgIACEL5USmtKgygOrOz9Xcpmu4rNLLnUWAgoAPUnDqz+TL+kfklSbv+sYmAtXHjMrqhTBBSAupVeNXT1lFYUWL273lC+b2jJJUYE1i8CCkDDKLfkUu+uBcrcNqe45FIpugTDRkABaCzDl1zKbVZ/9qkRu5V2CXKFFSYCCkBjS6WULnOVVNolmLltztAbzLkKBgEFoGkVuwTz0fOt+gfnFrsEmXOVPAIKQHMbMedqs1b37S3OucofnqHMQBRYBFVtEVAAUGrEnKsosLJbosnBBQRW9RFQADCaQmD13lVsWj2wLAqsQeZcVVMiAWVmyyT9uaQLJaXcfUeF/RZJ+ltJp0h6wN3vrlmRABJ15a236tDBgyPaW6dM0dZ77ql9QSWXS2skqfcuLd++UvmeqG1Q7cy5mmBJXUH9XNJ1kr5XaQczO0XSfZI+K2m3pGfMbJO7v1CbEgEk6dDBg9oxZcqI9vllQisR3d1a331gaLv3Xi3fvlKZr7RLMzuKzQTWyUskoNz9RUkys9F2S0na6e4vx/s+JOlaSQQUgPB0d2v97M3qz04uNvXuWqDMV9rVfnmHZs+O2ugGHLuQ70GdI+nVku3dki6ttLOZrZC0QpLOnzatupUBQDnD5lxFIwIvUX77oPID0fJL2Z4WtV/ewQCLMahaQJnZk5LOLvPWne7+2ET/PHdfK2mtJM3v7PSJPj4AnLDCAIuS5ZdW912i7JYjygx2FR9zLzHXqpyqBZS7f2ach9gj6byS7XPjNgCoLyX9eoURgasHlg095n7f0IhAugCHhNzF94ykTjPrUBRM10v6w2RLAlArrVOmlB0Q0Vpm4ETd6e6ORgIWxCMCsz3tyva1Rm1tbU0fWOZe+94wM/u8pP8laZqkf5f0nLt/zszaFQ0nvybe7xpJ31Y0zPxBd/+LsRx/fmen70hiGCoAnKxcrviYe0lavn2lBhUNsCinkboEFy+2Z919/vD2RAKq2ggoAHUvl1N/drJy+2eNeCu7r0u6sHG6BCsFVMhdfADQvOIRgely7zVJlyABBQD1Jp5zNbxLMNvTrnx+aM6VVN+BRUABQD0qWYVdUnGScO/2BcU5V4OHW5TP1++cKwIKABpBoUtw2CPvM1vS0Srs8SPv29vrZ4AFAQUAjWT4I+9771L/4NxiWyGwFi5tC777j4ACgEbW3X3MQIt0PEk42zNP2Z64saU1yMAioACgmRQmCecejLbz+WJg5fNDc65mz05+gAUBBQDNqJA+qZTWSOrPbFBuYGjOVXb7vMQHWBBQAAClV3Ud0xXYn9kwNMAiVuvH3BNQAIAR0qu6lM6tK8616h+ce8wAi4JqdgMSUACA8krmWqUlpXPrtLrvEqkveju7r0vZvuqNCCSgAABjU3i+VUEcWNmeecpmhwZYTNSSSwQUAODkxIHVn9lQbMrtn1UMrIULy/6RMSOgAADjkl7VNfRaUWD17lqgfF/LMfsNHm5Rtm/sc64IKADAhIoGWGwu+165LsFKCCgAwMSrcIk0vEtQkp6qcAgCCgBQU6VdgpIqJtT7ql8KAAAnjoACAASJgAIABImAAgAEiYACAASJgAIABImAAgAEiYACAASJgAIABImAAgAEiYACAASJgAIABImAAgAEKZGAMrNlZva8mb1nZvNH2W+XmQ2Y2XNmtqOWNQIAkpXU4zZ+Luk6Sd8bw76/5+6vV7keAEBgEgkod39RkswsiR8PAKgDod+Dckn/bGbPmtmK0XY0sxVmtsPMdrx28GCNygMAVEvVrqDM7ElJZ5d56053f2yMh1ng7nvM7CxJT5jZL9z9J+V2dPe1ktZK0vzOTj+pogEAwahaQLn7ZybgGHvi7/vM7FFJKUllAwoA0FiC7eIzsw+YWUvhtaSrFA2uAAA0gaSGmX/ezHZLukzSP5nZj+P2djN7PN5tuqSnzOynknKS/sndNydRLwCg9pIaxfeopEfLtA9KuiZ+/bKkS2pcGgAgEMF28QEAmhsBBQAIEgEFAAgSAQUACBIBBQAIEgEFAAgSAQUACBIBBQAIEgEFAAgSAQUACBIBBQAIEgEFAAgSAQUACBIBBQAIEgEFAAgSAQUACBIBBQAIEgEFAAgSAQUACBIBBQAIEgEFAAgSAQUACBIBBQAIEgEFAAgSAQUACBIBBQAIEgEFAAgSAQUACBIBBQAIEgEFAAgSAQUACFIiAWVmf2VmvzCzn5nZo2b2wQr7LTKzX5rZTjO7vcZlAgASlNQV1BOSPuLuvyspL+mO4TuY2SmS7pN0taQuSTeYWVdNqwQAJCaRgHL3f3b3d+LNpyWdW2a3lKSd7v6yu78t6SFJ19aqRgBAsk5NugBJX5K0vkz7OZJeLdneLenSSgcxsxWSVsSbb9nixT+fsArrw5mSXk+6iBrjnJtHM553M53zh8o1Vi2gzOxJSWeXeetOd38s3udOSe9I+t/j/XnuvlbS2vi4O9x9/niPWU845+bQjOcsNed5N+M5D1e1gHL3z4z2vpndKOm/Sfq0u3uZXfZIOq9k+9y4DQDQBJIaxbdI0ipJi939Pyvs9oykTjPrMLPfkXS9pE21qhEAkKykRvF9R1KLpCfM7Dkz+ztJMrN2M3tckuJBFLdI+rGkFyVtcPfnx3j8tVWoOXScc3NoxnOWmvO8m/Gcj2Hle9cAAEgWK0kAAIJEQAEAgtQQAWVmy8zseTN7z8wqDstspKWTzOwMM3vCzH4Vf59aYb934/t8z5lZXQ4yOd7nZmbvN7P18fv/YmYzEyhzQo3hnG80s9dKPtsvJ1HnRDKzB81sn5mVncNokXvj/yY/M7O5ta5xoo3hnBea2cGSz/nPal1jkhoioCT9XNJ1kn5SaYcGXDrpdklb3L1T0pZ4u5wj7v7R+Gtx7cqbGGP83G6S9Ia7f1jStyR9s7ZVTqwT+Lu6vuSzfaCmRVZHj6RFo7x/taTO+GuFpPtrUFO19Wj0c5akbSWf8zdqUFMwGiKg3P1Fd//lcXZrtKWTrpX0g/j1DyQtSa6UqhrL51b63+IRSZ82M6thjROt0f6ujom7/0TSgVF2uVbS33vkaUkfNLMZtamuOsZwzk2tIQJqjMotnXROQrVMhOnuvjd+/W+SplfY73Qz22FmT5vZktqUNqHG8rkV94mnJxyU1FaT6qpjrH9Xl8ZdXY+Y2Xll3m80jfY7PFaXmdlPzexHZnZR0sXUUghr8Y3JWJZOajSjnXPphru7mVWaL/Ahd99jZhdI2mpmA+7+0kTXiprrl7TO3d8ysz9WdAV5ZcI1YeL9P0W/w2+a2TWSNirq4mwKdRNQx1s6aQzqbumk0c7ZzH5jZjPcfW/czbGvwjH2xN9fNrOspI9JqqeAGsvnVthnt5mdKmmKpP21Ka8qjnvO7l56fg9IytSgrqTV3e/weLn7oZLXj5vZd83sTHdvikVkm6mLr9GWTtok6Yvx6y9KGnEVaWZTzez98eszJX1S0gs1q3BijOVzK/1v8fuStlZY37FeHPech917WaxotZVGt0nS/4hH831C0sGSbu6GZGZnF+6nmllK0b/Z9fw/XyfG3ev+S9LnFfVHvyXpN5J+HLe3S3q8ZL9rFD0g8SVFXYOJ1z6Oc25TNHrvV5KelHRG3D5f0gPx68slDUj6afz9pqTrPslzHfG5SfqGorUcJel0SQ9L2ikpJ+mCpGuuwTn/paTn48/2/0iak3TNE3DO6yTtlXQ0/n2+SdLNkm6O3zdFoxtfiv8+z0+65hqc8y0ln/PTki5PuuZafrHUEQAgSM3UxQcAqCMEFAAgSAQUACBIBBQAIEgEFAAgSAQUEBgzO8/M/tXMzoi3p8bbM81ss5n9u5n9Y9J1AtVGQAGBcfdXFa3UfXfcdLekte6+S9JfSfrvCZUG1BQBBYTpW5I+YWZ/ImmBpL+WJHffIulwgnUBNVM3a/EBzcTdj5rZ1yVtlnSVux9Nuiag1riCAsJ1taJlcD6SdCFAEggoIEBm9lFJn5X0CUl/Wu8P5gNOBgEFBCZevfp+SX/i7r9WNDDir5OtCqg9AgoIzx9J+rW7PxFvf1fShWb2X81sm6KV2z9tZrvN7HOJVQlUGauZAwCCxBUUACBIBBQAIEgEFAAgSAQUACBIBBQAIEgEFAAgSAQUACBI/x9LfsEt1NwpSgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "Q3 = plot_decision_regions(X_Q3, Y_Q3, classifier=LGD_Q3)\n",
        "plt.xlabel('X1')\n",
        "plt.ylabel('X2')\n",
        "plt.legend(loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The decision boundry is closer to the class $y = 1$ (blue cross) than class $y = 0$ (red square)"
      ],
      "metadata": {
        "id": "O8w0QIwbrXuc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayVRy0pxlBDP"
      },
      "outputs": [],
      "source": [
        "# Grader's area\n",
        "\n",
        "maxScore = maxScore + 12\n",
        "# M[3,1] = \n",
        "# M[3,2] = \n",
        "# M[3,3] = "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2ZazaTq1GzQ"
      },
      "source": [
        "<font color = 'blue'> **Q3-4**.  </font> The standard scikit-learn implementation of logistic regression uses regularization by default ($C=1$).  Can you come up with a linearly separable dataset that makes that **default** implementation fail? <br>\n",
        "\n",
        "[Note: This is an experimental question. You should be able to use the example from above, or modify it, and make the default implementation fail.]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "XN-VON-12oqM",
        "outputId": "2852c56a-294e-41f1-dc6d-5c5599627022"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-a8435fe16d39>:25: UserWarning: You passed a edgecolor/edgecolors ('black') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
            "  plt.scatter(x=X[y == cl, 0],\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "LR_Q3 = LogisticRegression(C=1, random_state=10, solver='lbfgs', multi_class='ovr')\n",
        "LR_Q3.fit(X_Q3, Y_Q3)\n",
        "\n",
        "plot_decision_regions(X_Q3, Y_Q3, classifier=LR_Q3)\n",
        "plt.xlabel('X1')\n",
        "plt.ylabel('X2')\n",
        "plt.legend(loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The decision area for class $y = 0$ (red area) includes a blue cross that belongs to class $y = 1$ when using the the standard scikit-learn implementation of logistic regression applies regularization by default ($C=1$) on a linearly separable dataset"
      ],
      "metadata": {
        "id": "yuWN6TtervH9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlN9ptsC2rz_"
      },
      "outputs": [],
      "source": [
        "# Grader's area\n",
        "\n",
        "maxScore = maxScore + 4\n",
        "# M[3,4] = "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kffsOAaln8C_"
      },
      "source": [
        "-----------------------\n",
        "-----------------------\n",
        "-----------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVUZKNB2kod6"
      },
      "source": [
        "##  <font color = 'blue'> **Question 4. SVC and classification margin**  </font>\n",
        "\n",
        "The Iris dataset defined in the above cells is linearly separable. \n",
        "\n",
        "<font color = 'blue'> **Q4-1.**  </font> Use a [linear SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html) to learn a hyperplane $y=w_1x_1 +w_2x_2 +b$ that maximizes the margin for this Iris dataset. In your answer, specify a setting for the hyperparameter $C$ that reduces the amount of regularization (that is, incentivizes very small slacks)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "q_z3kIsShW2J",
        "outputId": "e8fc17ad-ac8f-4c78-85ed-ad3955b79d96"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearSVC(C=1000)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC(C=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC(C=1000)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "SVC_Q4 = LinearSVC(C=1000)\n",
        "SVC_Q4.fit(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jm8FYkMZR_sy"
      },
      "source": [
        "<font color = 'blue'> **Q4-2.** </font> Extract the coefficients $w$ and the intercept $b$ from the learned SVC. Find the the 2-norm of $w$: let $s = \\|w\\|_2$.\n",
        "[Hint: Read the documentation in order to access the coefficients.] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eo3OEPqmSc0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72aed495-2d3d-4901-e864-ff008999f087"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.95584904  2.0763552 ]]\n",
            "[-0.35548631]\n",
            "2.2858036438391203\n"
          ]
        }
      ],
      "source": [
        "print(SVC_Q4.coef_)\n",
        "print(SVC_Q4.intercept_)\n",
        "\n",
        "from numpy import array  \n",
        "from numpy.linalg import norm\n",
        "\n",
        "s = norm(SVC_Q4.coef_,2)\n",
        "print(s)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The coefficients are:\n",
        "\n",
        "*   $w_1 = -0.95585927$\n",
        "*   $w_2 = 2.07633716$\n",
        "*   Intercept $b = -0.35548755$\n",
        "\n",
        "The 2-norm of $w$ is $s = 2.2857915348502713$"
      ],
      "metadata": {
        "id": "DRxL5faOj8my"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBojlP6aSB4O"
      },
      "source": [
        "<font color = 'blue'> **Q4-3.** </font> Set $w \\leftarrow w/s$ and $b\\leftarrow b/s$. This changes the numerical definition of the separation line, but the line is still the same.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w91_qXfjSdId",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e7253cf-1b12-4b12-e286-866528587dc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w:  [-0.41816761  0.90836989]\n",
            "b:  -0.15551917911861907\n"
          ]
        }
      ],
      "source": [
        "w = SVC_Q4.coef_[0]/s\n",
        "b = SVC_Q4.intercept_[0]/s\n",
        "print('w: ', w)\n",
        "print('b: ', b)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The coefficients are:\n",
        "\n",
        "*   $w_1 = -0.41816761$\n",
        "*   $w_2 = 0.90836989$\n",
        "*   Intercept $b = -0.15551917911861907$"
      ],
      "metadata": {
        "id": "6f8T-OC48YTa"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnCBk3uQSDkh"
      },
      "source": [
        "<font color = 'blue'> **Q4-4.** </font> With the new $w$ and $b$, calculate $wx^T - b$ for each point $x$ in our dataset. This will give a range of values; let $\\gamma$ be the smallest of these in absolute value. This $\\gamma$ is the margin. (In fact, there should be two points $x_1$ and $x_2$ of different labels, that give $wx_1^T - b = \\gamma$ and $wx_1^T - b = -\\gamma$.)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Q4 = abs(np.dot(X, w) - b)\n",
        "\n",
        "margin = min(Q4)\n",
        "print('margin:', margin)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jjg-Ggjcmbtv",
        "outputId": "f8cdec0c-91b9-42c8-cecc-ffa301cfe857"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "margin: 0.1257825465768087\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The margin $\\gamma$ is 0.1258195571813479\n"
      ],
      "metadata": {
        "id": "38SPWnZ5t2-b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lp4N-D6VSJAQ"
      },
      "outputs": [],
      "source": [
        "# Grader's area\n",
        "\n",
        "maxScore = maxScore + 16\n",
        "# M[4,1] = \n",
        "# M[4,2] = \n",
        "# M[4,3] = \n",
        "# M[4,4] = "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTLcwDVan9x9"
      },
      "source": [
        "-----------------------\n",
        "-----------------------\n",
        "-----------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3ECKgmBD_aJ"
      },
      "source": [
        "##  <font color = 'blue'> **Question 5. Upper bound for perceptron errors before convergence**  </font>\n",
        "\n",
        "In this problem we will use the margin $\\gamma$ as calculated in Question 4. If you have not been able to calculate it, you can 'borrow' its value from someone else that has calculated it. (Feel free to share your calculated value of $\\gamma$ on Canvas, or to ask your peers to share theirs.)\n",
        "\n",
        "<font color = 'blue'> **Q5-1.** </font> Calculate $R = \\max_{x\\in X} \\|x\\|_2$. In other words, find the 2-norm of all points in the dataset, and let $R$ be the maximum norm. \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import array  \n",
        "from numpy.linalg import norm\n",
        "\n",
        "Q5_2Norm = []\n",
        "for i in range(len(X)):\n",
        "    n = norm(X[i], 2)\n",
        "    Q5_2Norm.append(n)\n",
        "\n",
        "R = max(Q5_2Norm)\n",
        "print('R: ', R)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bt4ALsg0uWsP",
        "outputId": "f569bfdb-b0f4-48fa-8059-4ccc5712d44e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R:  8.462860036654275\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " $R = \\max_{x\\in X} \\|x\\|_2 = 8.462860036654275$"
      ],
      "metadata": {
        "id": "IX4d4s4Yws1K"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7AVoMZrSWtM"
      },
      "source": [
        "<font color = 'blue'> **Q5-2.** </font> Calculate $\\mathit{maxErrors} = R/\\gamma^2$. This is the maximum number of errors that a perceptron can do, in the worst case, before it convergences. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UNQM1CjSZvm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc7ea964-25ca-4f2c-c77e-9f08916b7362"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "maxErrors:  534.904673086545\n"
          ]
        }
      ],
      "source": [
        "MaxErrors = R/(margin*margin)\n",
        "print('maxErrors: ', MaxErrors)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\mathit{maxErrors} = R/\\gamma^2 = 534.590028304151$"
      ],
      "metadata": {
        "id": "IhP3NUX-yBis"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEGfEvbwSYtR"
      },
      "source": [
        "<font color = 'blue'> **Q5-3.** </font> Compare $\\mathit{maxErrors}$ with the actual number of errors that the perceptron does with a random initialization. [Hint: Re-use the code from Assignment 2, or anything else that can provide you with that number].  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLgBGbh_SaHo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class Perceptron(object):\n",
        "    \"\"\"Perceptron classifier.\n",
        "\n",
        "    Parameters\n",
        "    ------------\n",
        "    eta : float\n",
        "      Learning rate (between 0.0 and 1.0)\n",
        "    n_iter : int\n",
        "      Passes over the training dataset.\n",
        "    random_state : int\n",
        "      Random number generator seed for random weight\n",
        "      initialization.\n",
        "\n",
        "    Attributes\n",
        "    -----------\n",
        "    w_ : 1d-array\n",
        "      Weights after fitting.\n",
        "    errors_ : list\n",
        "      Number of misclassifications (updates) in each epoch.\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, eta=0.01, n_iter=50, random_state=1):\n",
        "        self.eta = eta\n",
        "        self.n_iter = n_iter\n",
        "        self.random_state = random_state\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"Fit training data.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : {array-like}, shape = [n_examples, n_features]\n",
        "          Training vectors, where n_examples is the number of examples and\n",
        "          n_features is the number of features.\n",
        "        y : array-like, shape = [n_examples]\n",
        "          Target values.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        self : object\n",
        "\n",
        "        \"\"\"\n",
        "        rgen = np.random.RandomState(self.random_state)\n",
        "        self.w_ = rgen.normal(loc=0.0, scale=0.01, size=1 + X.shape[1])\n",
        "        self.errors_ = []\n",
        "        self.history_w_=[]\n",
        "\n",
        "        for _ in range(self.n_iter):\n",
        "            errors = 0\n",
        "            for xi, target in zip(X, y):\n",
        "                update = self.eta * (target - self.predict(xi))\n",
        "                self.w_[1:] += update * xi\n",
        "                self.w_[0] += update\n",
        "                errors += int(update != 0.0)\n",
        "                self.history_w_.append(self.w_)\n",
        "            \n",
        "            if (len(self.errors_) >= 1):\n",
        "                if self.errors_[-1]==0:\n",
        "                    print('Model Converged')\n",
        "                    break\n",
        "                      \n",
        "            self.errors_.append(errors)\n",
        "      \n",
        "        print('Iterations needed are ',_)\n",
        "        print(self.w_)\n",
        "        return self\n",
        "\n",
        "    def net_input(self, X):\n",
        "        \"\"\"Calculate net input\"\"\"\n",
        "        return np.dot(X, self.w_[1:]) + self.w_[0]\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Return class label after unit step\"\"\"\n",
        "        return np.where(self.net_input(X) >= 0.0, 1, -1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ppn = Perceptron(eta=0.00001, n_iter=100, random_state=1)\n",
        "\n",
        "ppn.fit(X, y)\n",
        "\n",
        "plt.plot(range(1, len(ppn.errors_) + 1), ppn.errors_, marker='o')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Number of updates')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "X1B30sIoyorq",
        "outputId": "8dd54442-ff8c-43ec-c0c9-77f25d821b1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Converged\n",
            "Iterations needed are  40\n",
            "[ 0.01528345 -0.00469356  0.00374228]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Total errors of Perceptron: ', sum(ppn.errors_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BJcKGgezOKF",
        "outputId": "93dd2bed-1b4a-4e5e-d079-4fe692492fb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total errors of Perceptron:  378\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The maximum number of errors that a perceptron can do, in the worst case, before it convergences $(\\mathit{maxErrors} = 534)$ is larger than the actual number of errors that the perceptron does with a random initialization $(\\mathit{totalErrors} = 378)$"
      ],
      "metadata": {
        "id": "tZE3brrizlZz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUts9oNyI4R7"
      },
      "outputs": [],
      "source": [
        "# Grader's area\n",
        "\n",
        "maxScore = maxScore + 12\n",
        "# M[5,1] = \n",
        "# M[5,2] = \n",
        "# M[5,3] = "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdAULOJaI_2h"
      },
      "source": [
        "----------------------------\n",
        "----------------------------\n",
        "----------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVkneTzYCAxs"
      },
      "outputs": [],
      "source": [
        "# Grader's area\n",
        "\n",
        "rawScore = np.sum(M)\n",
        "score = rawScore*100/maxScore"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}