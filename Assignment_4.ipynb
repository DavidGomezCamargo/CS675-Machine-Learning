{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tajfsk_7JY3E"
      },
      "source": [
        "**Note to grader:** Each question consists of parts, e.g. Q1(i), Q1(ii), etc. Each part must be graded  on a 0-4 scale, following the standard NJIT convention (A:4, B+: 3.5, B:3, C+: 2.5, C: 2, D:1, F:0). \n",
        "The total score must be re-scaled to 100 &mdash; that should apply to all future assignments so that Canvas assigns the same weight on all assignments. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Grader's area\n",
        "import numpy as np\n",
        "M = np.zeros([10,10])\n",
        "maxScore = 0"
      ],
      "metadata": {
        "id": "zPnHTf9MfT5X"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SArgW_Vq-uTh"
      },
      "source": [
        "# **Assignment 4**\n",
        "\n",
        "The goal of this assignment is to run some experiments with scikit-learn on a fairly sizeable and interesting image data set. This is the MNIST data set, which consists of tens of thousands of images, each having 28x28 pixels. By today's standards, this dataset may seem relatively tiny, but only a few years ago was quite challenging computationally, and it motivated the development of several ML algorithms and models that are now state-of-the-art  solutions for much bigger data sets. \n",
        "\n",
        "The assignment is experimental. We will try to whether a combination of PCA and kNN can yield any good results for the MNIST data set. Let's see if it can be made to work on this data set. \n",
        "\n",
        "Note: There are less difficult Python parts in this assignment. You can get things done by just using code snippets from the class notebooks (no attribution is needed for this). But your participation and interaction via Canvas is always appreciated!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlFM4hig-uTj"
      },
      "source": [
        "## Preparation Steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3alYkjM-uTk"
      },
      "source": [
        "# Import all necessary python packages\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JEBC9tZEZel",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "baf5c327-425e-400a-a42b-9ed138f7fb21"
      },
      "source": [
        "# We load the data set directly from scikit learn.\n",
        "# Note: this operation may take a few seconds.\n",
        "# If for any reason it fails we can revert back to loading from local storage. \n",
        "\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
        "y = y.astype(int)\n",
        "X = ((X / 255.) - .5) * 2    # Line A for Question 1(v)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=10000, random_state=123, stratify=y)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfrfDK0P-uT5"
      },
      "source": [
        "## <font color = 'blue'> Question 1. Inspecting the Dataset </font>\n",
        "\n",
        "**(i)** How many data points are in the training and test sets? <br>\n",
        "**(ii)** How many attributes does the data set have?\n",
        "\n",
        "Explain how you found the answer to the first two questions. \n",
        "\n",
        "[**Hint**: Use the 'shape' method associated with numpy arrays.]\n",
        "\n",
        "**(iii)** How many different labels does this data set have? Can you demonstrate how to read that number from the vector of labels *y_train*?  <br>\n",
        "**(iv)** How does the number of attributes relate to the size of the images? <br>\n",
        "**(v)** What is the role of Line A in the above code? \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*(Please insert cells below for your answers. Clearly identify the part of the question you are answering)*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### (i) How many data points are in the training and test sets?\n",
        "\n",
        "print(\"y_train shape: \", y_train.shape)\n",
        "print(\"y_test shape: \", y_test.shape)"
      ],
      "metadata": {
        "id": "x7YLk8-UQ5XO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8ef1802-a8c1-48c8-83fc-2f2f8f1f6916"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_train shape:  (60000,)\n",
            "y_test shape:  (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 60,000 data points in the traning set and 10,000 data points in the test set."
      ],
      "metadata": {
        "id": "Gp1xwcXZL0TJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### (ii) How many attributes does the data set have?\n",
        "\n",
        "print(\"X_train shape: \", X_train.shape)\n",
        "print(\"X_test shape: \", X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8przqL8M8UP",
        "outputId": "2a88425f-bd33-4e5e-d7e5-774387cd1c3a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape:  (60000, 784)\n",
            "X_test shape:  (10000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 784 attributes in the dataset.\n",
        "<br>\n",
        "The dimensions of the array are represented in the form of a tuple when we associate the shape() method with the NumPy array."
      ],
      "metadata": {
        "id": "O6MvKuP2NSK1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### (iii) How many different labels does this data set have? Can you demonstrate how to read that number from the vector of labels y_train?\n",
        "\n",
        "Q1_iii = y_train.unique()\n",
        "print('Different labels: ', Q1_iii)\n",
        "print('There are', len(Q1_iii), 'different labels.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nO1domvNi_H",
        "outputId": "e95bfddb-bc3c-4726-ac23-1b3add213b49"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Different labels:  [4 8 7 0 5 2 6 9 3 1]\n",
            "There are 10 different labels.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 10 different labels in the dataset."
      ],
      "metadata": {
        "id": "UhAoHobTONTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### (iv) How does the number of attributes relate to the size of the images?"
      ],
      "metadata": {
        "id": "l98xn26dOqDK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the assignment description, this is the MNIST data set, which consists of tens of thousands of images, each having 28x28 pixels, which means there are 784 pixels for each image.\n",
        "<br>\n",
        "There are 784 attributes in the dataset, therefore, each pixel information for each image is available as an attribute. This is how the number of attributes relate to the size of the images."
      ],
      "metadata": {
        "id": "A1PShEbJO1cf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### (v) What is the role of Line A in the above code?"
      ],
      "metadata": {
        "id": "-_x7oCPPPjuN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the dataset consists of tens of thousands of images, the color spectrum is represented in discrete values, where basic colors are represented in 8 bits, so they are each limited to 256 (2^8), that's the reason for dividing by 256 (255 in this case since 0 is included) before normalization.\n",
        "<br>\n",
        "Therefore, the role of Line A in the above code is to standarize the values of each pixel by calculating the difference from the midpoint (0.5) and dividing by 2, so the range would be between 0 and 1."
      ],
      "metadata": {
        "id": "MvTLh3s4QOkY"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IllLoXxGAIIo"
      },
      "source": [
        "# For grader use only\n",
        "\n",
        "# In this case, make excetion and, assign 0-2 points for each subquestion\n",
        "\n",
        "# Insert grade here  \n",
        "# G[1,1] = \n",
        "# G[1,2] =\n",
        "# G[1,3] = \n",
        "# G[1,4] = \n",
        "# G[1,5] =  \n",
        "\n",
        "maxScore = maxScore + 10"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMEcdAp3-uT-"
      },
      "source": [
        "##  <font color = 'blue'> Question 2. PCA on MNIST </font>\n",
        "\n",
        "Because the number of attributes of the MNIST data set may be too big to apply kNN on it (due to the 'curse of dimensionality'), we would like to compress the images down to a smaller number of transformed attributes. \n",
        "\n",
        "Use scikit-learn to output a data set *X_train_transformed* and *X_test_transformed*, with $l$ attributes. Here a reasonable choice of $l$ is 10, equal to the number of labels. But you can try slightly smaller or larger values as well. \n",
        "\n",
        "\n",
        "**Hint**: Take a look at [this notebook](https://colab.research.google.com/drive/1DG5PjWejo8F7AhozHxj8329SuMtXZ874?usp=drive_fs) we used in the lecture, and imitate what we did there. Be sure to use only the scikit-learn demonstration, not the exhaustive PCA steps we did before it.\n",
        "\n",
        "**Note**: This computation can take a while! If problems are encountered, we can try the same experiment on a downsized data set. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "Q2 = PCA(n_components = 10).fit(X_train)\n",
        "X_train_transformed = Q2.transform(X_train)\n",
        "X_test_transformed = Q2.transform(X_test)\n",
        "print('X_train_transformed: ', X_train_transformed)\n",
        "print('X_test_transformed: ', X_test_transformed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhavDLCCSzwG",
        "outputId": "269c31a5-399a-4c6a-ef20-a997765f52a2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_transformed:  [[ 0.0343793   5.93042881 -1.32557812 ...  0.80217255  0.79794175\n",
            "   0.24868201]\n",
            " [ 1.71107123  0.61959336 -5.61616294 ... -1.9073887   4.23969742\n",
            "   0.72691489]\n",
            " [-3.70015373  6.08597842 -2.92447796 ...  3.91635367 -3.01700488\n",
            "   1.98420708]\n",
            " ...\n",
            " [-1.38016639 -7.54467965  0.50226135 ...  0.45954821  0.99674125\n",
            "   0.98841315]\n",
            " [ 1.20194877  7.38339809 -1.3696067  ... -0.36823836  4.36173203\n",
            "   2.0124995 ]\n",
            " [-1.08511146 -4.05124447 -6.87142278 ...  5.18843696 -1.13764208\n",
            "  -0.03940527]]\n",
            "X_test_transformed:  [[-3.03519079e+00 -1.98450509e+00  1.13102089e+00 ... -8.83340827e-02\n",
            "   3.01250125e+00 -1.37865055e+00]\n",
            " [-2.40049599e+00  6.22497731e+00  3.36797431e-03 ... -9.45511471e-01\n",
            "  -1.76314790e+00  1.41808662e+00]\n",
            " [ 3.00133263e+00  1.35338455e+00 -1.65932928e-01 ...  2.03890463e+00\n",
            "  -2.93489497e-01 -7.54813961e-01]\n",
            " ...\n",
            " [ 5.16858174e+00 -3.04103502e+00  2.89070528e+00 ...  5.93433907e+00\n",
            "  -4.42940692e+00 -1.31594500e+00]\n",
            " [-5.94360768e+00 -1.19968886e+00 -1.18192821e-01 ... -2.89798580e-01\n",
            "  -2.00639142e+00 -2.31074563e+00]\n",
            " [-4.71396054e+00 -8.16036361e-01 -1.46922121e+00 ... -9.15454896e-01\n",
            "  -3.15666365e+00  3.32340286e+00]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBjMZF1wGaUp"
      },
      "source": [
        "# For grader use\n",
        "\n",
        "maxScore = maxScore +4 \n",
        "\n",
        "# insert grade here (out of 4)\n",
        "# G[2,1] ="
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pe9kKR3J-uUA"
      },
      "source": [
        "## <font color = 'blue'> Question 3. kNN on MNIST attributes from PCA </font>\n",
        "\n",
        "\n",
        "Having created a *transformed* MNIST data set, we can now apply a kNN approach. Here are the steps:\n",
        "\n",
        "(i) Fit a $k$-NN classifier on the transformed data set. Here $k$ is a hyperparameter, and you can experiment with it. Be aware though, that larger values of $k$ can take more time to fit. \n",
        "\n",
        "(ii) Apply the classifier on the transformed test set. What is the classification accuracy? \n",
        "\n",
        "(iii) A theoretical question: if we skipped all the above steps and we just assigned a **random** label to each test point, what would the classification accuracy be on average?  Is your result from (ii) better than the random expectation? \n",
        "\n",
        "(iv) Experiment with different settings of $k$, and other hyperparameters that are described in the scikit-learn manual of the kNN classifier. Report your findings in a separate cell. Also for **participation points**: report your best result on Canvas! \n",
        "\n",
        "[**Hint**: Imitate the steps from the classroom notebook]\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5v7Q2NKp-uUM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "c2fe01cc-8056-4dbc-e26f-7ffd15e29fc9"
      },
      "source": [
        "### (i) Fit a  k-NN classifier on the transformed data set.\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "Q3 = KNeighborsClassifier(n_neighbors=5,\n",
        "                           weights='distance',\n",
        "                           algorithm='kd_tree'\n",
        "                          )\n",
        "Q3.fit(X_train_transformed, y_train)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='kd_tree', weights='distance')"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(algorithm=&#x27;kd_tree&#x27;, weights=&#x27;distance&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(algorithm=&#x27;kd_tree&#x27;, weights=&#x27;distance&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### (ii) Apply the classifier on the transformed test set. What is the classification accuracy?\n",
        "\n",
        "Q3_Predicted = Q3.predict(X_test_transformed)\n",
        "print('The classification accuracy is', Q3.score(X_test_transformed,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4cxEKKQUlym",
        "outputId": "57f20822-537c-498e-c0a2-676a443a0e23"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification accuracy is 0.9354\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The classification accuracy is 0.9354 (93.54%)."
      ],
      "metadata": {
        "id": "OpYVJW8XU79E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### (iii) If we skipped all the above steps and we just assigned a random label to each test point, what would the classification accuracy be on average?\n",
        "### Is your result from (ii) better than the random expectation?\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "Q3_iii = np.random.choice(y.unique(),size=len(y_test))\n",
        "print('If a random label is assigned to each test point, the classification accuracy is', accuracy_score(Q3_iii,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuGrKrYBVSJf",
        "outputId": "91008cca-7ef7-4e34-c8bb-b0a4854c790a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "If a random label is assigned to each test point, the classification accuracy is 0.1039\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If a random label is assigned to each test point, the classification accuracy is 0.1039 (10.39%) on average.\n",
        "<br>\n",
        "Therefore, the accuracy with the random lables classifier is much lower than the PCA followed by KNN classifier (93.54%)."
      ],
      "metadata": {
        "id": "L17D6Rh1VPZw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### (iv) Experiment with different settings of  k, and other hyperparameters that are described in the scikit-learn manual of the kNN classifier.\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=5, \n",
        "                           weights='distance',\n",
        "                           algorithm='kd_tree'\n",
        "                          )\n",
        "knn.fit(X_train_transformed, y_train)\n",
        "Q3_1 = knn.predict(X_test_transformed)\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=5, \n",
        "                           weights='distance',\n",
        "                           algorithm='ball_tree'\n",
        "                          )\n",
        "knn.fit(X_train_transformed, y_train)\n",
        "Q3_2 = knn.predict(X_test_transformed)\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=5,\n",
        "                           weights='distance',\n",
        "                            algorithm='brute'\n",
        "                          )\n",
        "knn.fit(X_train_transformed, y_train)\n",
        "Q3_3 = knn.predict(X_test_transformed)\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=5,\n",
        "                           weights='uniform',\n",
        "                           algorithm='kd_tree'\n",
        "                          )\n",
        "knn.fit(X_train_transformed, y_train)\n",
        "Q3_4 = knn.predict(X_test_transformed)\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=5,\n",
        "                           weights='uniform',\n",
        "                           algorithm='ball_tree'\n",
        "                          )\n",
        "knn.fit(X_train_transformed, y_train)\n",
        "Q3_5 = knn.predict(X_test_transformed)\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=5,\n",
        "                           weights='uniform',\n",
        "                            algorithm='brute'\n",
        "                          )\n",
        "knn.fit(X_train_transformed, y_train)\n",
        "Q3_6 = knn.predict(X_test_transformed)\n",
        "\n",
        "print('Accuracy for k = 5, weights = distance, algorithm = kd_tree', accuracy_score(y_test, Q3_1))\n",
        "print('Accuracy for k = 5, weights = distance, algorithm = ball_tree', accuracy_score(y_test, Q3_2))\n",
        "print('Accuracy for k = 5, weights = distance, algorithm = brute', accuracy_score(y_test, Q3_3))\n",
        "print('Accuracy for k = 5, weights = uniform, algorithm = kd_tree', accuracy_score(y_test, Q3_4))\n",
        "print('Accuracy for k = 5, weights = uniform, algorithm = ball_tree', accuracy_score(y_test, Q3_5))\n",
        "print('Accuracy for k = 5, weights = uniform, algorithm = brute', accuracy_score(y_test, Q3_6))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njh-V796XIbN",
        "outputId": "70618afe-cfc6-4406-eb7c-bd2aaa057daa"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for k = 5, weights = distance, algorithm = kd_tree 0.9354\n",
            "Accuracy for k = 5, weights = distance, algorithm = ball_tree 0.9354\n",
            "Accuracy for k = 5, weights = distance, algorithm = brute 0.9354\n",
            "Accuracy for k = 5, weights = uniform, algorithm = kd_tree 0.9347\n",
            "Accuracy for k = 5, weights = uniform, algorithm = ball_tree 0.9347\n",
            "Accuracy for k = 5, weights = uniform, algorithm = brute 0.9347\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=10, \n",
        "                           weights='distance',\n",
        "                           algorithm='kd_tree'\n",
        "                          )\n",
        "knn.fit(X_train_transformed, y_train)\n",
        "Q3_7 = knn.predict(X_test_transformed)\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=10, \n",
        "                           weights='distance',\n",
        "                           algorithm='ball_tree'\n",
        "                          )\n",
        "knn.fit(X_train_transformed, y_train)\n",
        "Q3_8 = knn.predict(X_test_transformed)\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=10,\n",
        "                           weights='distance',\n",
        "                            algorithm='brute'\n",
        "                          )\n",
        "knn.fit(X_train_transformed, y_train)\n",
        "Q3_9 = knn.predict(X_test_transformed)\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=10,\n",
        "                           weights='uniform',\n",
        "                           algorithm='kd_tree'\n",
        "                          )\n",
        "knn.fit(X_train_transformed, y_train)\n",
        "Q3_10 = knn.predict(X_test_transformed)\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=10,\n",
        "                           weights='uniform',\n",
        "                           algorithm='ball_tree'\n",
        "                          )\n",
        "knn.fit(X_train_transformed, y_train)\n",
        "Q3_11 = knn.predict(X_test_transformed)\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=10,\n",
        "                           weights='uniform',\n",
        "                            algorithm='brute'\n",
        "                          )\n",
        "knn.fit(X_train_transformed, y_train)\n",
        "Q3_12 = knn.predict(X_test_transformed)\n",
        "\n",
        "print('Accuracy for k = 10, weights = distance, algorithm = kd_tree', accuracy_score(y_test, Q3_7))\n",
        "print('Accuracy for k = 10, weights = distance, algorithm = ball_tree', accuracy_score(y_test, Q3_8))\n",
        "print('Accuracy for k = 10, weights = distance, algorithm = brute', accuracy_score(y_test, Q3_9))\n",
        "print('Accuracy for k = 10, weights = uniform, algorithm = kd_tree', accuracy_score(y_test, Q3_10))\n",
        "print('Accuracy for k = 10, weights = uniform, algorithm = ball_tree', accuracy_score(y_test, Q3_11))\n",
        "print('Accuracy for k = 10, weights = uniform, algorithm = brute', accuracy_score(y_test, Q3_12))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yt2bfjqjcAD2",
        "outputId": "362fbfa5-b0d8-442d-808e-e7e83d12bfcc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for k = 10, weights = distance, algorithm = kd_tree 0.9346\n",
            "Accuracy for k = 10, weights = distance, algorithm = ball_tree 0.9346\n",
            "Accuracy for k = 10, weights = distance, algorithm = brute 0.9346\n",
            "Accuracy for k = 10, weights = uniform, algorithm = kd_tree 0.9328\n",
            "Accuracy for k = 10, weights = uniform, algorithm = ball_tree 0.9328\n",
            "Accuracy for k = 10, weights = uniform, algorithm = brute 0.9328\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=15, \n",
        "                           weights='distance',\n",
        "                           algorithm='kd_tree'\n",
        "                          )\n",
        "knn.fit(X_train_transformed, y_train)\n",
        "Q3_13 = knn.predict(X_test_transformed)\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=15, \n",
        "                           weights='distance',\n",
        "                           algorithm='ball_tree'\n",
        "                          )\n",
        "knn.fit(X_train_transformed, y_train)\n",
        "Q3_14 = knn.predict(X_test_transformed)\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=15,\n",
        "                           weights='distance',\n",
        "                            algorithm='brute'\n",
        "                          )\n",
        "knn.fit(X_train_transformed, y_train)\n",
        "Q3_15 = knn.predict(X_test_transformed)\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=15,\n",
        "                           weights='uniform',\n",
        "                           algorithm='kd_tree'\n",
        "                          )\n",
        "knn.fit(X_train_transformed, y_train)\n",
        "Q3_16 = knn.predict(X_test_transformed)\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=15,\n",
        "                           weights='uniform',\n",
        "                           algorithm='ball_tree'\n",
        "                          )\n",
        "knn.fit(X_train_transformed, y_train)\n",
        "Q3_17 = knn.predict(X_test_transformed)\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=15,\n",
        "                           weights='uniform',\n",
        "                            algorithm='brute'\n",
        "                          )\n",
        "knn.fit(X_train_transformed, y_train)\n",
        "Q3_18 = knn.predict(X_test_transformed)\n",
        "\n",
        "print('Accuracy for k = 15, weights = distance, algorithm = kd_tree', accuracy_score(y_test, Q3_13))\n",
        "print('Accuracy for k = 15, weights = distance, algorithm = ball_tree', accuracy_score(y_test, Q3_14))\n",
        "print('Accuracy for k = 15, weights = distance, algorithm = brute', accuracy_score(y_test, Q3_15))\n",
        "print('Accuracy for k = 15, weights = uniform, algorithm = kd_tree', accuracy_score(y_test, Q3_16))\n",
        "print('Accuracy for k = 15, weights = uniform, algorithm = ball_tree', accuracy_score(y_test, Q3_17))\n",
        "print('Accuracy for k = 15, weights = uniform, algorithm = brute', accuracy_score(y_test, Q3_18))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlnV4Dgub6Be",
        "outputId": "ce1e6033-b714-482a-ddfd-90d6070c475e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for k = 15, weights = distance, algorithm = kd_tree 0.9325\n",
            "Accuracy for k = 15, weights = distance, algorithm = ball_tree 0.9325\n",
            "Accuracy for k = 15, weights = distance, algorithm = brute 0.9325\n",
            "Accuracy for k = 15, weights = uniform, algorithm = kd_tree 0.9311\n",
            "Accuracy for k = 15, weights = uniform, algorithm = ball_tree 0.9311\n",
            "Accuracy for k = 15, weights = uniform, algorithm = brute 0.9311\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=20, \n",
        "                           weights='distance',\n",
        "                           algorithm='kd_tree'\n",
        "                          )\n",
        "knn.fit(X_train_transformed, y_train)\n",
        "Q3_19 = knn.predict(X_test_transformed)\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=20, \n",
        "                           weights='distance',\n",
        "                           algorithm='ball_tree'\n",
        "                          )\n",
        "knn.fit(X_train_transformed, y_train)\n",
        "Q3_20 = knn.predict(X_test_transformed)\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=20,\n",
        "                           weights='distance',\n",
        "                            algorithm='brute'\n",
        "                          )\n",
        "knn.fit(X_train_transformed, y_train)\n",
        "Q3_21 = knn.predict(X_test_transformed)\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=20,\n",
        "                           weights='uniform',\n",
        "                           algorithm='kd_tree'\n",
        "                          )\n",
        "knn.fit(X_train_transformed, y_train)\n",
        "Q3_22 = knn.predict(X_test_transformed)\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=20,\n",
        "                           weights='uniform',\n",
        "                           algorithm='ball_tree'\n",
        "                          )\n",
        "knn.fit(X_train_transformed, y_train)\n",
        "Q3_23 = knn.predict(X_test_transformed)\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=20,\n",
        "                           weights='uniform',\n",
        "                           algorithm='brute'\n",
        "                          )\n",
        "knn.fit(X_train_transformed, y_train)\n",
        "Q3_24 = knn.predict(X_test_transformed)\n",
        "\n",
        "print('Accuracy for k = 20, weights = distance, algorithm = kd_tree', accuracy_score(y_test, Q3_19))\n",
        "print('Accuracy for k = 20, weights = distance, algorithm = ball_tree', accuracy_score(y_test, Q3_20))\n",
        "print('Accuracy for k = 20, weights = distance, algorithm = brute', accuracy_score(y_test, Q3_21))\n",
        "print('Accuracy for k = 20, weights = uniform, algorithm = kd_tree', accuracy_score(y_test, Q3_22))\n",
        "print('Accuracy for k = 20, weights = uniform, algorithm = ball_tree', accuracy_score(y_test, Q3_23))\n",
        "print('Accuracy for k = 20, weights = uniform, algorithm = brute', accuracy_score(y_test, Q3_24))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QHnTAvzblNu",
        "outputId": "03acad0e-bb56-4575-8976-5d24aacfeaf3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for k = 20, weights = distance, algorithm = kd_tree 0.9315\n",
            "Accuracy for k = 20, weights = distance, algorithm = ball_tree 0.9315\n",
            "Accuracy for k = 20, weights = distance, algorithm = brute 0.9315\n",
            "Accuracy for k = 20, weights = uniform, algorithm = kd_tree 0.9288\n",
            "Accuracy for k = 20, weights = uniform, algorithm = ball_tree 0.9288\n",
            "Accuracy for k = 20, weights = uniform, algorithm = brute 0.9288\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=30, \n",
        "                           weights='distance',\n",
        "                           algorithm='kd_tree'\n",
        "                          )\n",
        "knn.fit(X_train_transformed, y_train)\n",
        "Q3_25 = knn.predict(X_test_transformed)\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=30, \n",
        "                           weights='distance',\n",
        "                           algorithm='ball_tree'\n",
        "                          )\n",
        "knn.fit(X_train_transformed, y_train)\n",
        "Q3_26 = knn.predict(X_test_transformed)\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=30,\n",
        "                           weights='distance',\n",
        "                            algorithm='brute'\n",
        "                          )\n",
        "knn.fit(X_train_transformed, y_train)\n",
        "Q3_27 = knn.predict(X_test_transformed)\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=20,\n",
        "                           weights='uniform',\n",
        "                           algorithm='kd_tree'\n",
        "                          )\n",
        "knn.fit(X_train_transformed, y_train)\n",
        "Q3_28 = knn.predict(X_test_transformed)\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=30,\n",
        "                           weights='uniform',\n",
        "                           algorithm='ball_tree'\n",
        "                          )\n",
        "knn.fit(X_train_transformed, y_train)\n",
        "Q3_29 = knn.predict(X_test_transformed)\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=30,\n",
        "                           weights='uniform',\n",
        "                           algorithm='brute'\n",
        "                          )\n",
        "knn.fit(X_train_transformed, y_train)\n",
        "Q3_30 = knn.predict(X_test_transformed)\n",
        "\n",
        "print('Accuracy for k = 30, weights = distance, algorithm = kd_tree', accuracy_score(y_test, Q3_25))\n",
        "print('Accuracy for k = 30, weights = distance, algorithm = ball_tree', accuracy_score(y_test, Q3_26))\n",
        "print('Accuracy for k = 30, weights = distance, algorithm = brute', accuracy_score(y_test, Q3_27))\n",
        "print('Accuracy for k = 30, weights = uniform, algorithm = kd_tree', accuracy_score(y_test, Q3_28))\n",
        "print('Accuracy for k = 30, weights = uniform, algorithm = ball_tree', accuracy_score(y_test, Q3_29))\n",
        "print('Accuracy for k = 30, weights = uniform, algorithm = brute', accuracy_score(y_test, Q3_30))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eAnO9WEe24R",
        "outputId": "aef17ae2-4738-4b85-bba1-9d1ddc58bcf7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for k = 30, weights = distance, algorithm = kd_tree 0.9282\n",
            "Accuracy for k = 30, weights = distance, algorithm = ball_tree 0.9282\n",
            "Accuracy for k = 30, weights = distance, algorithm = brute 0.9282\n",
            "Accuracy for k = 30, weights = uniform, algorithm = kd_tree 0.9288\n",
            "Accuracy for k = 30, weights = uniform, algorithm = ball_tree 0.926\n",
            "Accuracy for k = 30, weights = uniform, algorithm = brute 0.926\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The best result I was able to find was an accuracy of 93.54% using k = 20, distance weight with kd_tree, ball_tree and brute algorithm.\n",
        "<br>\n",
        "The accuracy scores tend to decrease as k increases (overfitting).\n",
        "<br>\n",
        "The accuracy scores tend to stay the same while using different algorithms (kd_tree, ball_tree and brute).\n",
        "<br>\n",
        "The accuracy scores tend to increase for weights = distance than uniform."
      ],
      "metadata": {
        "id": "jHKp0J5TcZdQ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuYcPkCaGe9p"
      },
      "source": [
        "# For grader use\n",
        "\n",
        "maxScore = maxScore +12\n",
        "\n",
        "# Insert grade here (each item out of 4)\n",
        "# G[3,1] =\n",
        "# G[3,2] = \n",
        "# G[3,3] =\n",
        "# G[3,4] = "
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fydXo8GRGkbp"
      },
      "source": [
        "# For grader use\n",
        "\n",
        "# Total Grade Calculation\n",
        "\n",
        "rawScore = np.sum(G)\n",
        "score = rawScore*100/maxScore"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}